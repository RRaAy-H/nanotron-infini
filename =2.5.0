Requirement already satisfied: torch in /Users/zhang/miniconda3/envs/infi-llama/lib/python3.10/site-packages (2.8.0)
Collecting flash-attn
  Using cached flash_attn-2.8.2.tar.gz (8.2 MB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'error'
